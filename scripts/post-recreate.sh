#!/usr/bin/env bash
# ------------------------------------------------------------
# Renda Cloud Lab Â· post-recreate.sh
# åŠŸèƒ½ï¼š
#   1. æ›´æ–°æœ¬åœ° kubeconfig ä»¥è¿æ¥æœ€æ–°åˆ›å»ºçš„é›†ç¾¤
#   2. é€šè¿‡ Helm å®‰è£…æˆ–å‡çº§ ${AUTOSCALER_RELEASE_NAME}
#   3. æ£€æŸ¥ NAT ç½‘å…³ã€ALBã€EKS æ§åˆ¶é¢å’ŒèŠ‚ç‚¹ç»„ç­‰çŠ¶æ€
#   4. è·å–æœ€æ–°çš„ EKS NodeGroup ç”Ÿæˆçš„ ASG åç§°
#   5. è‹¥ä¹‹å‰æœªç»‘å®šï¼Œåˆ™ä¸ºè¯¥ ASG é…ç½® SNS Spot Interruption é€šçŸ¥
#   6. è‡ªåŠ¨å†™å…¥ç»‘å®šæ—¥å¿—ï¼Œé¿å…é‡å¤æ‰§è¡Œ
# ä½¿ç”¨ï¼š
#   bash scripts/post-recreate.sh
# ------------------------------------------------------------

set -euo pipefail

# === å¯é…ç½®å‚æ•° ===
CLOUD_PROVIDER="aws"
PROFILE="phase2-sso"
REGION="us-east-1"

CLUSTER_NAME="dev"
NODEGROUP_NAME="ng-mixed"
KUBE_DEFAULT_NAMESPACE="kube-system"
ASG_PREFIX="eks-${NODEGROUP_NAME}"
ACCOUNT_ID="563149051155"
TOPIC_NAME="spot-interruption-topic"
TOPIC_ARN="arn:${CLOUD_PROVIDER}:sns:${REGION}:${ACCOUNT_ID}:${TOPIC_NAME}"
STATE_FILE="scripts/.last-asg-bound"
AUTOSCALER_CHART_NAME="cluster-autoscaler"
AUTOSCALER_RELEASE_NAME=${AUTOSCALER_CHART_NAME}
AUTOSCALER_ROLE_NAME="eks-cluster-autoscaler"
AUTOSCALER_ROLE_ARN="arn:${CLOUD_PROVIDER}:iam::${ACCOUNT_ID}:role/${AUTOSCALER_ROLE_NAME}"
DEPLOYMENT_AUTOSCALER_NAME="${AUTOSCALER_RELEASE_NAME}-${CLOUD_PROVIDER}-${AUTOSCALER_CHART_NAME}"
POD_AUTOSCALER_LABEL="app.kubernetes.io/name=${AUTOSCALER_RELEASE_NAME}"

# === å‡½æ•°å®šä¹‰ ===
log() {
  echo "[$(date '+%Y-%m-%d %H:%M:%S')] $*"
}

# æ›´æ–° kubeconfig ä»¥è¿æ¥ EKS é›†ç¾¤
update_kubeconfig() {
  log "ğŸ”„ æ›´æ–° kubeconfig ä»¥è¿æ¥ EKS é›†ç¾¤: $CLUSTER_NAME"
  aws eks update-kubeconfig \
    --region "$REGION" \
    --name "$CLUSTER_NAME" \
    --profile "$PROFILE"
}

# æ£€æŸ¥ Cluster Autoscaler éƒ¨ç½²çŠ¶æ€
check_autoscaler_status() {
  if ! kubectl -n $KUBE_DEFAULT_NAMESPACE get deployment $DEPLOYMENT_AUTOSCALER_NAME >/dev/null 2>&1; then
    echo "missing"
    return
  fi
  if kubectl -n $KUBE_DEFAULT_NAMESPACE get pod -l $POD_AUTOSCALER_LABEL \
      --no-headers 2>/dev/null | grep -v Running >/dev/null; then
    echo "unhealthy"
  else
    echo "healthy"
  fi
}

# å®‰è£…æˆ–å‡çº§ Cluster Autoscaler
install_autoscaler() {
  local status
  status=$(check_autoscaler_status)
  case "$status" in
    healthy)
      log "âœ… Cluster Autoscaler å·²æ­£å¸¸è¿è¡Œ, è·³è¿‡ Helm éƒ¨ç½²"
      return 0
      ;;
    missing)
      log "âš™ï¸  æ£€æµ‹åˆ° Cluster Autoscaler æœªéƒ¨ç½², å¼€å§‹å®‰è£…"
      ;;
    unhealthy)
      log "âŒ æ£€æµ‹åˆ° Cluster Autoscaler çŠ¶æ€å¼‚å¸¸, åˆ é™¤æ—§ Pod åé‡æ–°éƒ¨ç½²"
      kubectl -n $KUBE_DEFAULT_NAMESPACE delete pod -l $POD_AUTOSCALER_LABEL --ignore-not-found
      ;;
    *)
      log "âš ï¸  æœªçŸ¥çš„ Cluster Autoscaler çŠ¶æ€, ç»§ç»­å°è¯•å®‰è£…"
      ;;
  esac
  log "ğŸš€ æ­£åœ¨é€šè¿‡ Helm å®‰è£…æˆ–å‡çº§ Cluster Autoscaler..."
  if ! helm repo list | grep -q '^autoscaler'; then
    log "ğŸ”§ æ·»åŠ  autoscaler Helm ä»“åº“"
    helm repo add autoscaler https://kubernetes.github.io/autoscaler
  fi
  helm repo update
  # è·å– Kubernetes å®Œæ•´ç‰ˆæœ¬ (å¦‚ v1.33.1)
  K8S_FULL_VERSION=$(kubectl version -o json | jq -r '.serverVersion.gitVersion')
  # æå–ä¸»æ¬¡ç‰ˆæœ¬å· (å¦‚ 1.33)
  K8S_MINOR_VERSION=$(echo "$K8S_FULL_VERSION" | sed -E 's/^v([0-9]+\.[0-9]+)\..*$/\1/')
  # ç¡®å®š Cluster Autoscaler ç‰ˆæœ¬ (æ€»æ˜¯ä½¿ç”¨ .0 è¡¥ä¸ç‰ˆæœ¬)
  AUTOSCALER_VERSION="v${K8S_MINOR_VERSION}.0"
  helm upgrade --install ${AUTOSCALER_RELEASE_NAME} autoscaler/${AUTOSCALER_CHART_NAME} -n $KUBE_DEFAULT_NAMESPACE --create-namespace \
    --set awsRegion=$REGION \
    --set autoDiscovery.clusterName=$CLUSTER_NAME \
    --set rbac.serviceAccount.create=true \
    --set rbac.serviceAccount.name=${AUTOSCALER_RELEASE_NAME} \
    --set extraArgs.balance-similar-node-groups=true \
    --set extraArgs.skip-nodes-with-system-pods=false \
    --set rbac.serviceAccount.annotations."eks\\.amazonaws\\.com/role-arn"="$AUTOSCALER_ROLE_ARN" \
    --set image.tag=$AUTOSCALER_VERSION
  log "âœ… Helm install completed"
  log "ğŸ” æ£€æŸ¥ Cluster Autoscaler Pod çŠ¶æ€"
  kubectl -n $KUBE_DEFAULT_NAMESPACE get pod -l $POD_AUTOSCALER_LABEL
  log "å¦‚æœ Helm éƒ¨ç½²å¤±è´¥ï¼Œé‡æ–°éƒ¨ç½²åï¼Œéœ€è¦æ‰§è¡Œå¦‚ä¸‹å‘½ä»¤åˆ é™¤æ—§ Pod è®© Deployment æ‹‰æ–°é…ç½®: "
  log "kubectl -n $KUBE_DEFAULT_NAMESPACE delete pod -l $POD_AUTOSCALER_LABEL"
}

# è·å–å½“å‰æœ€æ–° ASG å
get_latest_asg() {
  aws autoscaling describe-auto-scaling-groups \
    --region "$REGION" --profile "$PROFILE" \
    --query "AutoScalingGroups[?starts_with(AutoScalingGroupName, \`${ASG_PREFIX}\`)].AutoScalingGroupName" \
    --output text | head -n1
}

# ç»‘å®š SNS é€šçŸ¥
bind_sns_notification() {
  local asg_name="$1"
  log "ğŸ”„ ç»‘å®š SNS é€šçŸ¥åˆ° ASG: $asg_name"
  aws autoscaling put-notification-configuration \
    --auto-scaling-group-name "$asg_name" \
    --topic-arn "$TOPIC_ARN" \
    --notification-types "autoscaling:EC2_INSTANCE_TERMINATE" \
    --region "$REGION" --profile "$PROFILE"
}

# ç¡®ä¿ SNS ç»‘å®šåˆ°æœ€æ–° ASG
ensure_sns_binding() {
  local asg_name="$1"
  if [[ -z "$asg_name" ]]; then
    log "âŒ æœªæ‰¾åˆ°ä»¥ $ASG_PREFIX å¼€å¤´çš„ ASG, ç»ˆæ­¢è„šæœ¬"
    exit 1
  fi
  if [[ -f "$STATE_FILE" ]]; then
    last_bound_asg=$(cat "$STATE_FILE")
  else
    last_bound_asg=""
  fi
  if [[ "$asg_name" == "$last_bound_asg" ]]; then
    log "âœ… å½“å‰ ASG [$asg_name] å·²ç»‘å®šè¿‡, æ— éœ€é‡å¤ç»‘å®š"
  else
    bind_sns_notification "$asg_name"
    echo "$asg_name" > "$STATE_FILE"
    log "âœ… å·²ç»‘å®šå¹¶è®°å½•æœ€æ–° ASG: $asg_name"
  fi
}

# æ£€æŸ¥ NAT ç½‘å…³çŠ¶æ€
check_nat_gateway() {
  aws ec2 describe-nat-gateways \
    --region "$REGION" --profile "$PROFILE" \
    --query "NatGateways[?State=='available']" --output json | jq length
}

# æ£€æŸ¥ ALB çŠ¶æ€
check_alb() {
  aws elbv2 describe-load-balancers \
    --region "$REGION" --profile "$PROFILE" \
    --query "LoadBalancers[?Type=='application']" --output json | jq length
}

# æ£€æŸ¥ EKS é›†ç¾¤çŠ¶æ€
check_eks_cluster() {
  aws eks describe-cluster \
    --region "$REGION" --profile "$PROFILE" \
    --name "$CLUSTER_NAME" \
    --query 'cluster.status' --output text
}

# æ£€æŸ¥èŠ‚ç‚¹ç»„çŠ¶æ€
check_nodegroup() {
  aws eks describe-nodegroup \
    --region "$REGION" --profile "$PROFILE" \
    --cluster-name "$CLUSTER_NAME" \
    --nodegroup-name "$NODEGROUP_NAME" \
    --query 'nodegroup.status' --output text
}

# æ£€æŸ¥æ—¥å¿—ç»„å­˜åœ¨
check_log_group() {
  aws logs describe-log-groups \
    --region "$REGION" --profile "$PROFILE" \
    --log-group-name-prefix "/aws/eks/${CLUSTER_NAME}/cluster" \
    --query 'logGroups[*].logGroupName' --output text
}

# æ£€æŸ¥ SNS ç»‘å®š
check_sns_binding() {
  local asg_name="$1"
  aws autoscaling describe-auto-scaling-groups \
    --region "$REGION" --profile "$PROFILE" \
    --auto-scaling-group-names "$asg_name" \
    --query "AutoScalingGroups[0].NotificationConfigurations[?TopicARN=='${TOPIC_ARN}']" \
    --output json | jq length
}

# è¿›è¡ŒåŸºç¡€èµ„æºæ£€æŸ¥
perform_health_checks() {
  local asg_name="$1"
  log "ğŸ” å¼€å§‹æ‰§è¡ŒåŸºç¡€èµ„æºå¥åº·æ£€æŸ¥..."
  log "ğŸ” æ£€æŸ¥ NAT ç½‘å…³çŠ¶æ€"
  nat_count=$(check_nat_gateway)
  log "NAT Gateway count: $nat_count"
  log "ğŸ” æ£€æŸ¥ ALB çŠ¶æ€"
  alb_count=$(check_alb)
  log "ALB count: $alb_count"
  log "ğŸ” æ£€æŸ¥ EKS é›†ç¾¤çŠ¶æ€"
  eks_status=$(check_eks_cluster)
  log "EKS cluster status: $eks_status"
  log "ğŸ” æ£€æŸ¥èŠ‚ç‚¹ç»„çŠ¶æ€"
  node_status=$(check_nodegroup)
  log "NodeGroup status: $node_status"
  log "ğŸ” æ£€æŸ¥ LogGroup æ˜¯å¦å­˜åœ¨"
  log_group=$(check_log_group)
  log "LogGroup: $log_group"
  log "ğŸ” æ£€æŸ¥ Cluster Autoscaler éƒ¨ç½²çŠ¶æ€"
  autoscaler_status=$(check_autoscaler_status)
  log "Cluster Autoscaler status: $autoscaler_status"
  log "ğŸ” éªŒè¯ SNS é€šçŸ¥ç»‘å®š"
  sns_bound=$(check_sns_binding "$asg_name")
  log "SNS bindings for ASG [$asg_name]: $sns_bound"
}

# === ä¸»æµç¨‹ ===
log "ğŸ“£ å¼€å§‹æ‰§è¡Œ post-recreate è„šæœ¬"

update_kubeconfig

install_autoscaler

log "ğŸ” è·å–æœ€æ–°çš„ ASG åç§°"
asg_name=$(get_latest_asg)

ensure_sns_binding "$asg_name"

perform_health_checks "$asg_name"
